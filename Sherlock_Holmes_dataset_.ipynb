{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TK14j4lCIHMltVeQwniY1tYa_N8Z0qYT",
      "authorship_tag": "ABX9TyNPOOA+jR1hHJVxqbEQlwVW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shamiul-693/-Exploratory-Data-Analysis-and-Classification-Algorithms-on-Mushroom-Dataset/blob/main/Sherlock_Holmes_dataset_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5FyAZuUCFkcm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load_dataset(folder_path):\n",
        "    stories = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
        "                stories.append(file.read())\n",
        "    return stories\n",
        "\n",
        "# Your extraction path\n",
        "folder_path = \"/content/drive/MyDrive/ Sherlock /sherlock\"\n",
        "stories = load_dataset(folder_path)\n",
        "\n",
        "# Check the number of stories loaded\n",
        "print(f\"Loaded {len(stories)} stories.\")\n"
      ],
      "metadata": {
        "id": "vDoF5krWqFLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07043fd-8cf0-4c48-89b9-1eb55a953647"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 67 stories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Ensure required NLTK resources are downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# Download the 'punkt_tab' resource\n",
        "nltk.download('punkt_tab') # This line downloads the missing resource.\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation and special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize whitespace\n",
        "    tokens = word_tokenize(text)  # Tokenize\n",
        "    stop_words = set(stopwords.words('english'))  # Load stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply preprocessing to all stories\n",
        "cleaned_stories = [preprocess_text(story) for story in stories]\n",
        "\n",
        "# Example: Print the first 500 characters of the first cleaned story\n",
        "print(cleaned_stories[0][:500])"
      ],
      "metadata": {
        "id": "jvL7gPbfqFJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42684e0b-f005-4376-8411-db935e5ede2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adventure beryl coronet arthur conan doyle holmes said stood one morning bowwindow looking street madman coming along seems rather sad relatives allow come alone friend rose lazily armchair stood hands pockets dressinggown looking shoulder bright crisp february morning snow day still lay deep upon ground shimmering brightly wintry sun centre baker street ploughed brown crumbly band traffic either side heapedup edges footpaths still lay white fell grey pavement cleaned scraped still dangerously s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = [\n",
        "    \"Summary of story 1\",\n",
        "    \"Summary of story 2\",\n",
        "    # Add for all stories\n",
        "]\n"
      ],
      "metadata": {
        "id": "eBKrwyJ1qFEs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "\n",
        "# Calculate vocabulary size (you'll need to adapt this based on your data)\n",
        "# Assuming 'cleaned_stories' is a list of preprocessed stories (strings)\n",
        "all_words = \" \".join(cleaned_stories).split()\n",
        "vocab_size = len(set(all_words)) + 1  # +1 for unknown words (usually denoted by 0)\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None, vocab_size))\n",
        "encoder_lstm = LSTM(256, return_state=True)\n",
        "_, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None, vocab_size))\n",
        "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ],
      "metadata": {
        "id": "SrguV58lqFCZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Assuming 'cleaned_stories' contains the preprocessed stories:\n",
        "combined_text = \"\\n\\n\".join(cleaned_stories)  # Join the stories with double newlines\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = [model.encode(paragraph) for paragraph in combined_text.split(\"\\n\\n\")]"
      ],
      "metadata": {
        "id": "qQqk6C0MqFAG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "65T6NdKkqE-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ya6oRLxBqE7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IqRvIrJwqE5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AwEcTQ84qE2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZHVOaFoqE0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LoCz5WQSqEyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AC_Lav6QqEvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RYVbTX26qEtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9UCanCzkqEqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RTwUdDr5qEob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G3_k2vGlqEmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "USNWdORqqEjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mhv667vSqEhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sOLVZBmSqEeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "do07422SqEb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p32nzPM7qEZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TmcZ2FWsqEXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S4FwWJp1qEUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXrKS6u2qEPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CHfMWZS8qENY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k1kKjgZMqELS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_-1tk953qEIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N6e4iBzqqEGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LbmM0B8fqED1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BHvQyCaBqEBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LB4MRjSxqD_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q9oduB9gqD9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WUTsrvWMqD6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "efdd4zBUqD4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8UhoDajpqD2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uk4vFnnsqD0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ExlYKK3uqDx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aDNTcsqAqDvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yCCX3R7UqDtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXFJ2M8NqDoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "53OLmuhhqDmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oQfs1f_bqDkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6yy1H_yTqDh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7frfFtkgqDfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_TYP4qJJqDc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "63q0yqm1qDah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s14p8qeWqDYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "100FLHWRqDWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0hqLpZ4yqDUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wNHPmTltqDQ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}